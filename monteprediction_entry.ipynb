{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microprediction/monteprediction_colab_examples/blob/main/monteprediction_entry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sector Monte Carlo Game\n",
        "\n",
        "I'm looking for people to help blow away traditional index investing as the world knows it, using a novel meritocracy. Those who choose to be part of this new venture submit one million scenarios for next week's sector returns, and do so every weekend. Each scenario comprises 11 numbers, one for each financial sector. Every week the following are updated:\n",
        "\n",
        "*   [Weekly likelihood scores](https://www.monteprediction.com/weekly)\n",
        "*   [Wealth](https://www.monteprediction.com/)\n",
        "\n",
        "Loosely speaking you are rewarded based on how many of your samples are close to the ground truth (and in the case of wealth, how many of your competitors are also close - precise details below).\n",
        "\n",
        "You can participate by running this notebook.\n",
        "\n",
        "* Change the email and name below and, prefereably,\n",
        "* Modify this example notebook first to *improve the algorithm* (and I mean *completely replace it* as you see fit).  \n",
        "\n",
        "Once you get the joke, you'll need to script this up to run it every weekend.\n",
        "\n"
      ],
      "metadata": {
        "id": "8wu0RqylugX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install scipy\n",
        "!pip install --upgrade monteprediction\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from monteprediction import SPDR_ETFS\n",
        "from monteprediction.calendarutil import get_last_wednesday\n",
        "from monteprediction.submission import send_in_chunks\n",
        "\n",
        "# Tournament settings, don't change these.\n",
        "num_samples_per_chunk = int(1048576/8)\n",
        "num_chunks = 8\n",
        "num_samples = num_chunks*num_samples_per_chunk"
      ],
      "metadata": {
        "id": "mx0ZUY32_CAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1. Create a dataframe with just over one million hypothetical weekly returns for each sector.   \n",
        "\n",
        "Do this however you like this is just an example. One column per sector."
      ],
      "metadata": {
        "id": "PWvz4C7vBVVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This example uses Quasi-Monte Carlo on the empirical covariance\n",
        "# There is absolutely no requirement you follow this pattern\n",
        "\n",
        "from scipy.stats.qmc import MultivariateNormalQMC\n",
        "from sklearn.covariance import EmpiricalCovariance\n",
        "\n",
        "# Get historical weekly returns\n",
        "last_wednesday = get_last_wednesday()\n",
        "num_weeks = int(52+4*52*np.random.rand())\n",
        "start_date = last_wednesday - timedelta(weeks=num_weeks)\n",
        "data = yf.download(SPDR_ETFS, start=start_date, end=last_wednesday, interval=\"1wk\")\n",
        "weekly_prices = data['Adj Close']\n",
        "weekly_returns = weekly_prices.pct_change().dropna()\n",
        "\n",
        "# Use cov estimation to generate samples\n",
        "cov_matrix = EmpiricalCovariance().fit(weekly_returns).covariance_\n",
        "qmc_engine = MultivariateNormalQMC(mean=np.zeros(len(SPDR_ETFS)), cov=cov_matrix)\n",
        "samples = qmc_engine.random(num_samples)\n",
        "df = pd.DataFrame(columns=SPDR_ETFS, data = samples)\n",
        "print(df[:3])\n",
        "\n",
        "# Verify submission\n",
        "assert len(df.index)==num_samples,f'Expecting exactly {num_samples} samples'\n",
        "assert list(df.columns)==SPDR_ETFS,'Columns should match SPDR_ETFS in order'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZtSzrXdBL__",
        "outputId": "a4c02fa2-e46e-4480-ee55-195cf31e9a63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  11 of 11 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        XLB       XLC       XLE       XLF       XLI       XLK       XLP  \\\n",
            "0 -0.005739 -0.027379  0.055381 -0.005150 -0.007348 -0.037388  0.036084   \n",
            "1  0.017681  0.012907 -0.007036  0.046401  0.040037  0.062786  0.021175   \n",
            "2  0.051049  0.020684  0.054569  0.026398  0.034945  0.029755  0.021246   \n",
            "\n",
            "       XLRE       XLU       XLV       XLY  \n",
            "0  0.005877  0.045887  0.014344 -0.043577  \n",
            "1  0.032060  0.006658 -0.002639  0.068654  \n",
            "2  0.022588  0.006153  0.004474  0.042195  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2. Submit the dataframe"
      ],
      "metadata": {
        "id": "UlqcDSD5DXNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_EMAIL = 'monteprediction_entry@monteprediction.com'  # Be sure to change this\n",
        "YOUR_NAME  = 'Original gangster'    # The handle to be used on the leaderboard\n",
        "response = send_in_chunks(df, num_chunks=num_chunks, email=YOUR_EMAIL, name=YOUR_NAME)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WwTq_rwDVB1",
        "outputId": "eec33079-bb18-43aa-976c-a3182f10b497"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 0 of 8 sent successfully.\n",
            "Chunk 1 of 8 sent successfully.\n",
            "Chunk 2 of 8 sent successfully.\n",
            "Chunk 3 of 8 sent successfully.\n",
            "Chunk 4 of 8 sent successfully.\n",
            "Chunk 5 of 8 sent successfully.\n",
            "Chunk 6 of 8 sent successfully.\n",
            "Chunk 7 of 8 sent successfully.\n",
            "{'expiry': '2024_05_20', 'message': 'Submission from monteprediction_entry@monteprediction.com received for week concluding 2024_05_20', 'name': 'Original gangster'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3. (Later, optional) verify the submission\n",
        "A more detailed check of your submission will be performed within 10-20 minutes of your submitting."
      ],
      "metadata": {
        "id": "M05VMSwPFSuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monteprediction.verification import get_verification_status\n",
        "import time\n",
        "time.sleep(15*60)\n",
        "print(get_verification_status(email=YOUR_EMAIL))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk3tZHQfFame",
        "outputId": "b092d7f9-c672-4782-aee2-adf079c11bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explaining the game ...\n",
        "Here's how the reward system works.\n",
        "\n",
        "### Weekly likelihood scores\n",
        "\n",
        "We will assume you are participant $i$. Let's write your samples as $\\{x_{ik}\\}_{k=0}^{n-1}$, where each $x_{ik}$ for $k=0,\\dots,2^{20}-1$ is an 11-vector. This will be used to imply an unnormalized prediction density for $z \\in \\mathbf{R}^{11}$ as:\n",
        "\n",
        "$$\\rho_i(z) = \\frac{1}{n} \\sum_{k=0}^{n-1} \\exp(-a \\|x_{ik}-z \\|_2) $$\n",
        "\n",
        "where $a$ is a system parameter set at approximately $a=300$. This is almost your score and approximately one week from now it will appear in the [weekly scoring](https://www.monteprediction.com/weekly). There is also an overall likelihood score although only available through the [api](https://www.monteprediction.com/api/scores) at time of writing.\n",
        "\n",
        "### Accumulated wealth\n",
        "\n",
        "There is also an [overall wealth](https://www.monteprediction.com/) computed for each player based on their longitudinal performance. To see how your wealth is updated each week, let us suppose you have an initial wealth $W_i$.\n",
        "\n",
        "A system parameter $b_i=0.1$ determines the fraction of your total wealth you deploy that week. You are considered to invest $\\Omega_i = b_i W_i$ and similarly for other participants yielding a total investment of $\\Omega = \\sum_i \\Omega_i$. This pot will be split when the truth $z$ is revealed.\n",
        "\n",
        "To this end your 'mass' is $Q_i(z) = \\Omega_i \\rho_i(z)$ represents loosely how many of your samples are close to $z$ weighted by your wealth. The total mass near $z$ supplied by all participants is $Q(z) = \\sum_i Q_i(z)$. Your payout is $\\Omega \\frac{Q_i(z)}{Q(z)}$ which may be thought of as your share of the mass near the truth. Your net profit is $\\delta_i(z) = \\Omega \\frac{Q_i(z)}{Q(z)} - \\Omega_i$ and that is what dictates how your wealth ticks up or down from one week to the next.   \n",
        "\n",
        "### Incentive\n",
        "\n",
        "It should be apparent that $Q$ plays the role of an unnormalized market probability (i.e. risk-neutral density) and further, that a participant with perfect knowledge of the true density $P$ will at worst break even against any opponents' play, subject only to the ability to approximate $P$ with a collection of Monte Carlo paths in this fashion.\n",
        "\n",
        "(Because this entry has been included in the mix, and is not particularly clever, there is a subsidy for participation for anyone taking even a moment to reflect statistically upon the problem ... for instance, by applying shrinkage to the covariance estimation or fixing the 1-margins).\n",
        "\n",
        "### Minor change to scoring Apr '24\n",
        "\n",
        "What's above isn't *entirely* true.\n",
        "\n",
        "In April it was decided by the community that it would be better to compute likelihoods using not only the likelihood for the 11-dimensional outcome, but also adding in the likelihoods for each 10-dimensional subspace with a lower weighting.\n",
        "\n",
        "It is hoped that this will reward more accurate predictions with greater statistical power (i.e. more skill versus luck). For avoidance of doubt you can always refer to the scoring code which is transparent and appears in the monteprediction package [here](https://github.com/microprediction/monteprediction/blob/main/monteprediction/scoring.py)."
      ],
      "metadata": {
        "id": "S38mSrPNDbsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... here's how you can verify your score...\n",
        "from monteprediction.truth import get_most_recent_truth\n",
        "from monteprediction.scoring import compute_score\n",
        "z = get_most_recent_truth()\n",
        "print({'z':z})\n",
        "score = compute_score(samples=df.values,z=z)\n",
        "print(f\"Score using your samples above last week: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNFHQsO4FW8j",
        "outputId": "db63d91b-3ca1-4065-baf7-73d63c10ed2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  11 of 11 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'z': array([-0.03072112, -0.01442068, -0.01988178, -0.03632423, -0.02204183,\n",
            "       -0.0049891 , -0.0127809 , -0.02970295, -0.01473307, -0.03009355,\n",
            "       -0.00967343])}\n",
            "Score using your samples above last week: 1.2029812637019566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some suggestions\n",
        "\n",
        "There are many critiques of this example entry, one that has been created solely to provide a template and illustrate the submission process, that might provoke you to create better entries.\n",
        "\n",
        "\n",
        "1.   The distributions for each sector are assumed normal\n",
        "2.   The joint distribution is assumed multivariate normal\n",
        "3.   The empirical distribution is used to estimate a covariance matrix, which is typically not a brilliant idea. See instead LedoitWolf or ShrunkCovariance from [sklearn.covariance](https://scikit-learn.org/stable/modules/covariance.html), for example. You can also avail yourself of dozens of other covariance estimation methods in the [precise](https://github.com/microprediction/precise/tree/main/precise/skaters/covariance) package.\n",
        "\n",
        "To emphasize, do not treat the above as normative in any way. If you prefer to create samples using a water computer, or copulas, or machine learning generative models (quite popular of late as per [this paper](https://cs230.stanford.edu/projects_fall_2019/reports/26259829.pdf) for example) then go for it.\n",
        "\n"
      ],
      "metadata": {
        "id": "kRDDZo6iyfMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leaderboard\n",
        "\n",
        "As noted, to go [www.monteprediction.com](www.monteprediction.com) for the weekly likelihood scores and accumulated wealth.\n",
        "\n",
        "## Scheduling\n",
        "\n",
        "This is a long-running tournament (perhaps forever) and the wealth will be taken rather seriously. Only those who contribute longitudinally will be rewarded (details to follow).\n",
        "\n",
        "So, it is very important to submit each and every week. I strongly suggest setting up a cron job to run on Saturdays, or otherwise ensuring that your entry is sent. There is a wealth penalty if you fail to submit.\n",
        "\n"
      ],
      "metadata": {
        "id": "xrJu9OJYoFIX"
      }
    }
  ]
}